{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOchn1Jcw5zta16HKfiCuw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "915676d752594823a21b2409c58d07d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c38f3e967b245849f4a7d0514591633",
              "IPY_MODEL_59f03d63e8744d4b9532737514d91fbe",
              "IPY_MODEL_b762a3184a704b41a0f8dbad58835837"
            ],
            "layout": "IPY_MODEL_7884703dc162415984d175ddda3f4c6f"
          }
        },
        "3c38f3e967b245849f4a7d0514591633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f9e200a8ab42ddbccf0468a27c2a55",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74c7c674ac1043bd9532416e63adb9d6",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá100%"
          }
        },
        "59f03d63e8744d4b9532737514d91fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c435e97c44044406a4559089d5919d85",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c7fd43d667e440ca56b5dbd7c7c749c",
            "value": 4203
          }
        },
        "b762a3184a704b41a0f8dbad58835837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b624f15a2cd341338a334b81cd9f1a5a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b8ca33fb0ed74056a50be0ba8d4ba50b",
            "value": "‚Äá4.20k/4.20k‚Äá[00:00&lt;00:00,‚Äá124kB/s]"
          }
        },
        "7884703dc162415984d175ddda3f4c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f9e200a8ab42ddbccf0468a27c2a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c7c674ac1043bd9532416e63adb9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c435e97c44044406a4559089d5919d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7fd43d667e440ca56b5dbd7c7c749c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b624f15a2cd341338a334b81cd9f1a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ca33fb0ed74056a50be0ba8d4ba50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude123studios/TradingBots/blob/main/NVIDIA_STOCK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY-IOBzIcmBM",
        "outputId": "f594c461-a33b-408a-d46b-a6dcd8476306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  publishedAt                                            content\n",
            "0  2025-02-07  OnePlus 13 review: A focused flagship that ign...\n",
            "1  2025-02-20  A $599 iPhone 16e is a cruel joke. The $599 iP...\n",
            "2  2025-02-13  Gemini Advanced can now recall your past conve...\n",
            "3  2025-02-12  Google will use machine learning to try and te...\n",
            "4  2025-02-27  iPhone 16e review: What's your acceptable comp...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define API key and base URL\n",
        "API_KEY = '658d2e0e1d4a4203babad16ca1612e72'\n",
        "BASE_URL = 'https://newsapi.org/v2/everything?'\n",
        "\n",
        "# Define search query\n",
        "query = 'NVIDIA OR GPU OR \"Artificial Intelligence\" OR AI'\n",
        "\n",
        "# Define date range\n",
        "end_date = datetime.today().date()\n",
        "start_date = end_date - timedelta(days=27)  # Past 3 months\n",
        "\n",
        "# Fetch articles\n",
        "url = (f\"{BASE_URL}q={query}&from={start_date}&to={end_date}\"\n",
        "       f\"&sortBy=popularity&pageSize=100&apiKey={API_KEY}\")  # Fetch top 100 articles\n",
        "\n",
        "response = requests.get(url)\n",
        "articles = response.json().get('articles', [])\n",
        "# Process articles into DataFrame\n",
        "news_data = []\n",
        "for article in articles:\n",
        "    if article['content']:  # Ensure the content is not None\n",
        "        news_data.append({\n",
        "            'publishedAt': article['publishedAt'][:100],\n",
        "            'content': article['title'] + \". \" + (article['description'] or \"\"),\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(news_data)\n",
        "df['publishedAt'] = pd.to_datetime(df['publishedAt']).dt.date\n",
        "\n",
        "# Limit to 10 articles per day\n",
        "df = df.groupby('publishedAt').head(10).reset_index(drop=True)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Step 2: Fetch NVIDIA & S&P 500 stock data\n",
        "nvidia_ticker = yf.Ticker(\"NVDA\")\n",
        "sp500_ticker = yf.Ticker(\"^GSPC\")  # S&P 500 Index\n",
        "\n",
        "# Fetch stock data from 3 months ago to today + 3 days (for labeling)\n",
        "stock_start = start_date - timedelta(days=1)\n",
        "stock_end = end_date + timedelta(days=3)\n",
        "\n",
        "nvda_prices = nvidia_ticker.history(start=stock_start, end=stock_end)[[\"Close\"]].reset_index()\n",
        "sp500_prices = sp500_ticker.history(start=stock_start, end=stock_end)[[\"Close\"]].reset_index()\n",
        "\n",
        "# Convert stock dates\n",
        "nvda_prices[\"Date\"] = nvda_prices[\"Date\"].dt.date\n",
        "sp500_prices[\"Date\"] = sp500_prices[\"Date\"].dt.date\n",
        "\n",
        "# Function to assign labels based on NVIDIA vs. S&P 500 performance\n",
        "def get_relative_label(news_date):\n",
        "    if news_date not in nvda_prices[\"Date\"].values or news_date not in sp500_prices[\"Date\"].values:\n",
        "        return None\n",
        "\n",
        "    # NVIDIA & S&P 500 closing prices on news day\n",
        "    nvda_close_today = nvda_prices.loc[nvda_prices[\"Date\"] == news_date, \"Close\"].values[0]\n",
        "    sp500_close_today = sp500_prices.loc[sp500_prices[\"Date\"] == news_date, \"Close\"].values[0]\n",
        "\n",
        "    # Look at 1-2 trading days ahead for stock movement\n",
        "    next_day = news_date + timedelta(days=1)\n",
        "    next2_day = news_date + timedelta(days=2)\n",
        "\n",
        "    while next_day not in nvda_prices[\"Date\"].values and next2_day not in nvda_prices[\"Date\"].values:\n",
        "        next_day += timedelta(days=1)\n",
        "        next2_day += timedelta(days=1)\n",
        "        if (next_day - news_date).days > 4:  # Skip weekends but avoid infinite loops\n",
        "            return None\n",
        "\n",
        "    # Find closest available stock data\n",
        "    nvda_close_future = nvda_prices.loc[nvda_prices[\"Date\"] == (next_day if next_day in nvda_prices[\"Date\"].values else next2_day), \"Close\"].values[0]\n",
        "    sp500_close_future = sp500_prices.loc[sp500_prices[\"Date\"] == (next_day if next_day in sp500_prices[\"Date\"].values else next2_day), \"Close\"].values[0]\n",
        "\n",
        "    # Calculate percentage change\n",
        "    nvda_return = ((nvda_close_future - nvda_close_today) / nvda_close_today) * 100\n",
        "    sp500_return = ((sp500_close_future - sp500_close_today) / sp500_close_today) * 100\n",
        "\n",
        "    # NVIDIA relative performance\n",
        "    relative_change = nvda_return - sp500_return\n",
        "\n",
        "    # Assign labels\n",
        "    if relative_change > 0.5:\n",
        "        return 0  # NVIDIA outperformed the market\n",
        "    elif relative_change < -0.5:\n",
        "        return 1  # NVIDIA underperformed\n",
        "    else:\n",
        "        return 2  # NVIDIA moved similarly to the market\n",
        "\n",
        "# Apply function to get labels\n",
        "df[\"sentiment\"] = df[\"publishedAt\"].apply(get_relative_label)\n",
        "\n",
        "# Remove rows where labels couldn't be assigned\n",
        "df = df.dropna(subset=[\"sentiment\"])\n",
        "\n",
        "# Save labeled dataset\n",
        "df.to_csv(\"nvidia_news_labeled.csv\", index=False)\n",
        "\n",
        "print(\"News dataset collected & labeled successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fl572xc_h-",
        "outputId": "95018af1-f394-41a2-ab67-31a097efeded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News dataset collected & labeled successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ej8YvKEAeV7",
        "outputId": "ead98583-045d-41dc-e75a-3fbdfb8d6c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)  # Convert logits to class predictions\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "915676d752594823a21b2409c58d07d8",
            "3c38f3e967b245849f4a7d0514591633",
            "59f03d63e8744d4b9532737514d91fbe",
            "b762a3184a704b41a0f8dbad58835837",
            "7884703dc162415984d175ddda3f4c6f",
            "29f9e200a8ab42ddbccf0468a27c2a55",
            "74c7c674ac1043bd9532416e63adb9d6",
            "c435e97c44044406a4559089d5919d85",
            "9c7fd43d667e440ca56b5dbd7c7c749c",
            "b624f15a2cd341338a334b81cd9f1a5a",
            "b8ca33fb0ed74056a50be0ba8d4ba50b"
          ]
        },
        "id": "1IkonUhD_X3X",
        "outputId": "15d7f788-f9dc-49cf-f3fc-26043ca2c72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "915676d752594823a21b2409c58d07d8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "# Custom Dataset class\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(int(label), dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['content'].tolist(), df['sentiment'].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_len=512)\n",
        "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_len=512)\n",
        "\n",
        "# Load pre-trained FinBERT model\n",
        "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=8,   # batch size for training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",     # evaluation frequency\n",
        "    save_strategy=\"epoch\",           # save model at the end of each epoch\n",
        "    load_best_model_at_end=True,     # load the best model when finished training\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the model to train\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"./finbert_nvidia_stock_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Ww5vzgaKm8J9",
        "outputId": "88acb8cf-d4c6-45ec-a8a6-c5fee29ce844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdude123studios\u001b[0m (\u001b[33mdude123studios-university-of-oxford\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250305_063729-juj2hyk3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dude123studios-university-of-oxford/huggingface/runs/juj2hyk3' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/dude123studios-university-of-oxford/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dude123studios-university-of-oxford/huggingface' target=\"_blank\">https://wandb.ai/dude123studios-university-of-oxford/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dude123studios-university-of-oxford/huggingface/runs/juj2hyk3' target=\"_blank\">https://wandb.ai/dude123studios-university-of-oxford/huggingface/runs/juj2hyk3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 15:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.243104</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.289300</td>\n",
              "      <td>2.207090</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.289300</td>\n",
              "      <td>2.154343</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"finbert_nvidia_stock_model_1\", 'zip', './finbert_nvidia_stock_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZZh8cRKPG4iR",
        "outputId": "e1c4e6bf-6796-4048-dadb-606fd8eeed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/finbert_nvidia_stock_model_1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"./finbert_nvidia\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dag42jMeICTC",
        "outputId": "9e87058e-d89f-4a45-8a35-6572f3cb30e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finbert_nvidia/tokenizer_config.json',\n",
              " './finbert_nvidia/special_tokens_map.json',\n",
              " './finbert_nvidia/vocab.txt',\n",
              " './finbert_nvidia/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load fine-tuned model\n",
        "finbert_sentiment = pipeline(\"text-classification\", model=\"./finbert_nvidia_stock_model\", tokenizer=\"./finbert_nvidia\")\n",
        "\n",
        "# Test on a new article\n",
        "test_text = \"NVIDIA reports record profits due to AI boom.\"\n",
        "result = finbert_sentiment(test_text)\n",
        "\n",
        "print(f\"Sentiment Prediction: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o689nAjQHr1Q",
        "outputId": "d4b7d3c8-e024-4298-9c8c-bc9f151c7b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Prediction: [{'label': 'Positive', 'score': 1.0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_2 = '''OpenAI announced on Thursday it is launching GPT-4.5, the much-anticipated AI model code-named Orion. GPT-4.5 is OpenAI‚Äôs largest model to date, trained using more computing power and data than any of the company‚Äôs previous releases.\n",
        "\n",
        "Despite its size, OpenAI notes in a whitepaper that it does not consider GPT-4.5 to be a frontier model.\n",
        "\n",
        "4-Pack Colorful Spring Cat Toys, Elastic Soft Tube Interactive Feline Playthings, High Visual Appeal Pet Supplies\n",
        "\n",
        "Subscribers to ChatGPT Pro, OpenAI‚Äôs $200-a-month plan, will gain access to GPT-4.5 in ChatGPT starting Thursday as part of a research preview. Developers on paid tiers of OpenAI‚Äôs API will also be able to use GPT-4.5 starting today. As for other ChatGPT users, customers signed up for ChatGPT Plus and ChatGPT Team should get the model sometime next week, an OpenAI spokesperson told TechCrunch.\n",
        "\n",
        "The industry has held its collective breath for Orion, which some consider to be a bellwether for the viability of traditional AI training approaches. GPT-4.5 was developed using the same key technique ‚Äì dramatically increasing the amount of computing power and data during a ‚Äúpre-training‚Äù phase called unsupervised learning ‚Äî that OpenAI used to develop GPT-4, GPT-3, GPT-2, and GPT-1.\n",
        "\n",
        "In every GPT generation before GPT-4.5, scaling up led to massive jumps in performance across domains including mathematics, writing, and coding. Indeed, OpenAI says that GPT-4.5‚Äôs increased size has given it ‚Äúa deeper world knowledge‚Äù and ‚Äúhigher emotional intelligence.‚Äù However, there are signs that the gains from scaling up data and computing are beginning to level off. On several AI benchmarks, GPT-4.5 falls short of newer AI ‚Äúreasoning‚Äù models from Chinese AI company DeepSeek, Anthropic, and OpenAI itself.'''\n",
        "\n",
        "result = finbert_sentiment(test_text_2)\n",
        "\n",
        "print(f\"Sentiment Prediction: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlBVcoSDIMHQ",
        "outputId": "a01382d4-f68b-4ed8-935f-3c92be9f4d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Prediction: [{'label': 'Neutral', 'score': 0.9988709092140198}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "import datetime\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Fetch Today's AI/NVIDIA/GPU-related News\n",
        "def fetch_latest_news(api_key):\n",
        "    today = (datetime.datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "    url = f\"https://newsapi.org/v2/everything?q=(NVIDIA OR GPU OR AI)&from={today}&sortBy=popularity&pageSize=10&apiKey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"articles\" in data:\n",
        "        articles = [article[\"title\"] + \". \" + article[\"description\"] for article in data[\"articles\"] if article[\"description\"]]\n",
        "        return articles\n",
        "    else:\n",
        "        print(\"Error fetching news:\", data)\n",
        "        return []\n",
        "\n",
        "# Step 2: Load the Fine-Tuned FinBERT Model\n",
        "model_path = \"./finbert_nvidia\"  # Change this to your model's path\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained('./finbert_nvidia_stock_model')\n",
        "model.eval()\n",
        "\n",
        "# Step 3: Predict NVIDIA Stock Movement\n",
        "def predict_stock_movement(news_articles):\n",
        "    predictions = []\n",
        "    label_map = {0: \"Stock Down\", 1: \"Stock Same\", 2: \"Stock Up\"}  # Ensure this matches your fine-tuning labels\n",
        "\n",
        "    for article in news_articles:\n",
        "        inputs = tokenizer(article, truncation=True, padding=True, return_tensors=\"pt\", max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        predictions.append((article, label_map[predicted_label]))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Step 4: Compute the Majority Prediction\n",
        "def majority_vote(predictions):\n",
        "    labels = [pred[1] for pred in predictions]  # Extract predicted labels\n",
        "    count = Counter(labels)  # Count occurrences\n",
        "    most_common_label = count.most_common(1)[0][0]  # Get most common label\n",
        "\n",
        "    print(\"\\n--- Majority Prediction Based on Today's News ---\")\n",
        "    print(f\"Stock Movement Prediction: {most_common_label}\")\n",
        "    print(\"Breakdown:\", count)\n",
        "\n",
        "# Step 5: Run the Prediction Pipeline\n",
        "api_key = \"658d2e0e1d4a4203babad16ca1612e72\"  # Replace with your NewsAPI key\n",
        "news_articles = fetch_latest_news(api_key)\n",
        "\n",
        "if news_articles:\n",
        "    predictions = predict_stock_movement(news_articles)\n",
        "\n",
        "    # Print individual predictions\n",
        "    for i, (article, prediction) in enumerate(predictions):\n",
        "        print(f\"News {i+1}: {article[:150]}...\")  # Print first 150 chars for readability\n",
        "        print(f\"Predicted Impact on NVIDIA Stock: {prediction}\\n\")\n",
        "\n",
        "    # Compute and Print Majority Result\n",
        "    majority_vote(predictions)\n",
        "else:\n",
        "    print(\"No news articles found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAvkToYDSdX2",
        "outputId": "f4ba3488-0b43-44cd-cb96-f0de6973308f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News 1: TCL's 60 series phones pack premium features without the high-end price. TCL is bringing AI smarts to $200 phones with a little help from the cloud....\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 2: New MacBook Air Coming This Week: What to Expect. Apple CEO Tim Cook teased a new product announcement this week, sharing a short video that says \"the...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 3: Researchers Find Less-Educated Areas Adopting AI Writing Tools Faster. An anonymous reader quotes a report from Ars Technica: Since the launch of Chat...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 4: Hijacking AirTag Infrastructure To Track Arbitrary Devices. In case you weren‚Äôt aware, Apple devices around you are constantly scanning for AirTags. N...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 5: The $1000 RTX 5070 Ti may be the new normal. Nvidia‚Äôs vendor partners are intent on keeping the prices of its 50-series graphics cards high. Recent re...\n",
            "Predicted Impact on NVIDIA Stock: Stock Same\n",
            "\n",
            "News 6: Dienstag: Lichtblick f√ºr Intel, Washingtons Kehrwende sorgt f√ºr Spekulationen. Tests von Nvidia und Broadcom + Unsicherheit in der Security-Branche + ...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 7: Nvidia-Aktien sacken ab: GPUs in gro√üem Umfang √ºber Singapur nach China gelangt?. Hohe Z√∂lle auf alle Waren aus Mexiko und Kanada haben die US-Aktienm...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 8: TSMC verdoppelt Zahl geplanter Chipfabriken in den USA. TSMC plant drei Chipfabriken in Arizona, und jetzt noch drei mehr. Das Investitionsvolumen sol...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "News 9: Samsung Galaxy S25's most promising feature is getting a Gemini Live boost. Google is adding Gemini Live integration to the Galaxy S25's Now Bar...\n",
            "Predicted Impact on NVIDIA Stock: Stock Same\n",
            "\n",
            "News 10: ASUS„ÅÆ„Ç≤„Éº„Éü„É≥„Ç∞„Éé„Éº„Éà„ÄÅÁã¨Á´ãGPU„Å™„ÅÑ„ÅÆ„Å´„Äé„É¢„É≥„Éè„É≥„ÉØ„Ç§„É´„Ç∫„Äè„ÇÇ„Çµ„ÇØ„Çµ„ÇØ. Image:ROGÁêÜÊÉ≥„ÅÆ1Âè∞„Åã„ÇÇ„Åó„Çå„Å™„ÅÑ„Åû„Åì„Çå„ÄÇASUS„Åã„ÇâÊñ∞„Åó„ÅÑ„Ç≤„Éº„Éü„É≥„Ç∞„Éé„Éº„ÉàPC„ÄåROGFlowZ132025GZ302„Äç„ÅåÁô∫Ë°®„Åï„Çå„Åæ„Åó„Åü„ÄÇZ13„Ç∑„É™„Éº„Ç∫„ÅØ„ÄÅ„Çø„Éñ„É¨„ÉÉ„Éà„ÅÆ„Çà„ÅÜ„Å™ËªΩÂø´„Åï„Å®È´ò„ÅÑ„Ç≤„Éº„Éü„É≥„Ç∞ÊÄßËÉΩ„ÇíÂÇô„Åà„Åü„Åã„Å™...\n",
            "Predicted Impact on NVIDIA Stock: Stock Down\n",
            "\n",
            "\n",
            "--- Majority Prediction Based on Today's News ---\n",
            "Stock Movement Prediction: Stock Down\n",
            "Breakdown: Counter({'Stock Down': 8, 'Stock Same': 2})\n"
          ]
        }
      ]
    }
  ]
}